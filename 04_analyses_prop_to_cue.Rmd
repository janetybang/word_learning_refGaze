---
title: "04 - Analyses for Proportion to the cue area"
author: "Janet Bang"
date: "August 19, 2019"
output:
  html_document:
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE, cache=FALSE)

```


This code includes the analyses for the proportion to the cue area.

Data: demographics  
1. participant: participant id  
2. group: ASD or TYP  
3. age_mos: age in months  
4. age_yrs: age in years  
5. language: dominant language of child is English or French  
6. sex: male or female  
7. block1: gaze or arrow condition of first block  
8-10. mother_ed/father_ed/highest_ed: 0 = high school or less; 1 = university or higher  



## Load libraries and functions
```{r}
library(tidyverse)
library(openxlsx)
library(lme4)
library(influence.ME)
library(emmeans)
library(lmerTest)
library(compute.es)
library(lattice)
library(pwr)
library(sjPlot)
library(psych)

theme_set(theme_bw())

source("./helper_functions/R_helperFunctions_WLdata.R")
```

# Proportion fixation duration
## Read in csv files
```{r}
fix_dur_wide <- read_csv("./data/fix_dur_wide.csv") 
demographics <- read.csv("./data/demographics.csv")
```


## Add language information and select variables for analysis
```{r}
# select language variable
language <- demographics %>% 
  select(c(participant, language, age_yrs))

# select variables for propcue
propcue <- fix_dur_wide %>% 
  select(c(participant, object, trial_num, motion, 
           group, seq, block, cueCond, 
           base_propFixDur_eye, base_propFixDur_arw,
           cue1and2sum_propFixDur_eye, cue1and2sum_propFixDur_arw)) %>% 
  left_join(language, by = "participant")
```


## Turn to long and create variable names
```{r}
# turn to long
propcue_long <- propcue %>% 
  gather(variable, value, base_propFixDur_eye, base_propFixDur_arw,
           cue1and2sum_propFixDur_eye, cue1and2sum_propFixDur_arw)

# create variables
propcue_long <- propcue_long %>% 
  mutate(video_phase = ifelse(grepl("base", propcue_long$variable), "base", "cue1and2sum"), 
         variable = "propFixDur",
         aoi_cue = ifelse(grepl("eye",  propcue_long$variable), "eye", "arw")) %>% 
  mutate(video_phase = plyr::revalue(video_phase, c("cue1and2sum" = "teaching"))) %>% 
  select(-variable)
```


## Identify when the cue condition matches the aoi cue and re-label aois in the no_match
(e.g., in the arrow condition, the area of gaze is re-labeled to "sunglasses")
```{r}
propcue_long2 <- propcue_long %>% 
  mutate(cue_match =  ifelse(cueCond == "arw" & aoi_cue == "arw", "cue_gaze_arrow", 
                      ifelse(cueCond== "eye" & aoi_cue == "eye", "cue_gaze_arrow", "cue_sunglasses_bar"))) %>% 
  mutate(area_of_interest = ifelse(cueCond == "arw" & aoi_cue == "eye", "sunglasses", 
                    ifelse(cueCond == "eye" & aoi_cue == "arw", "bar", 
                    ifelse(cueCond == "arw" & aoi_cue == "arw", "arrow", 
                    ifelse(cueCond == "eye" & aoi_cue == "eye", "gaze", "CHECK"))))) %>% 
  mutate(area_of_interest = factor(area_of_interest, levels = c("gaze", "bar", "arrow", "sunglasses"))) %>% 
  mutate(cueCond = factor(cueCond, levels = c("eye", "arw")))


# filter only teaching phase
propcue_long2_teaching <- propcue_long2 %>% 
  filter(video_phase == "teaching") %>% 
  mutate(motion = factor(motion, levels = c("static", "function")))
 
# plot of visual attention to all cue areas - included in supplemental information
ggplot(propcue_long2_teaching, aes(area_of_interest, value, fill = area_of_interest)) + 
  geom_boxplot() + 
  facet_wrap(~ motion + group) + 
  theme(text = element_text(size=20)) + 
  labs(x = "Area of Interest", y = "Propotion Looking Time") + 
  geom_jitter(alpha = .3)
ggsave("./figures/proportion_cue_all_aois.pdf", width = 11.5, height = 8, unit = "in")


# summary statistics for area of interest
propcue_long2_teaching %>% 
  group_by(participant, area_of_interest, group, motion) %>% 
  mutate(mean_part = mean(value), 
         mdn_part = median(value), 
         min_part = min(value), 
         max_part = max(value)) %>% 
  distinct(participant, area_of_interest, group, motion, mean_part, mdn_part, min_part, max_part) %>% 
  group_by(group, motion, area_of_interest) %>% 
  mutate(mean_group = mean(mean_part), 
         mdn_group = median(mdn_part),
         min_group = min(min_part), 
         max_group = max(max_part)) %>% 
  distinct(group, motion, area_of_interest, mean_group, mdn_group, min_group, max_group)

```


## Create dataframe to only include rows where cue condition matches the aoi cue
```{r}
propcue_full <- propcue_long2 %>% 
  filter(cue_match == "cue_gaze_arrow") %>% 
  mutate(motion = factor(motion, levels = c("static", "function")), 
         cueCond = factor(cueCond, levels = c("eye", "arw")), 
         aoi_cue = factor(aoi_cue, levels = c("eye", "arw")))

ggplot(propcue_full, aes(cueCond, value, fill = aoi_cue)) + 
  geom_boxplot() + 
  facet_wrap(~ motion + video_phase) + 
  geom_jitter(alpha = .3)
```


## Transform variables and re-order levels
```{r}
propcue_full <- propcue_full %>% 
  mutate(participant = factor(participant), 
         object = factor(object), 
         trial_num = factor(trial_num), 
         motion = factor(motion), 
         group = factor(group),
         block = factor(block), 
         cueCond = factor(cueCond), 
         video_phase = factor(video_phase), 
         language = factor(language)) %>% 
  mutate(motion = fct_relevel(motion, "static", "function"),
         group = fct_relevel(group, "TYP", "ASD"), 
         cueCond = fct_relevel(cueCond, "eye", "arw"))
```



## Visual analysis: distribution of DV
```{r}
ggplot(propcue_full, aes(x = value, fill = cueCond)) + 
  geom_density(alpha = .3) + 
  facet_wrap(~ motion + video_phase) 
```


## Create dataframes for matched groups
```{r}
propcue_match <- propcue_full %>% 
  filter(participant == 302 | participant == 304 | participant == 306 | participant == 310 |
         participant == 312 | participant == 314 | participant == 315 | participant == 318 |
         participant == 321 | participant == 322 | participant == 323 | participant == 324 |
         participant == 325 | participant == 326 | participant == 329 | participant == 331 |
         participant == 332 | participant == 333 | participant == 341 | participant == 347 |
         participant == 349 | participant == 402 | participant == 403 | participant == 404 |
         participant == 406 | participant == 407 | participant == 408 | participant == 409 |
         participant == 410 | participant == 412 | participant == 413 | participant == 414 |
         participant == 415 | participant == 416 | participant == 418 | participant == 420 |
         participant == 421 | participant == 424 | participant == 425 | participant == 427 |
         participant == 428 | participant == 429 | participant == 430 | participant == 433 |
         participant == 435 | participant == 439 | participant == 443 | participant == 445)

# this results in 24 td and 22 asd (2 asd dropped from eye tracking)
propcue_match %>% 
  distinct(participant,group) %>% 
  group_by(group) %>% 
  dplyr::count()
```


## Mixed models: full group of 41 TD and 22 ASD
```{r}
# comparing models with and without slope
m_propcue = lmerTest::lmer(sqrt(value) ~ cueCond * video_phase * motion * group + 
                        (1 | participant),
                        data = propcue_full, REML = F) 

m_propcue_withslope = lmerTest::lmer(sqrt(value) ~ cueCond * video_phase * motion * group + 
                        (1 + cueCond | participant),
                        data =  propcue_full, REML = F) 

anova(m_propcue, m_propcue_withslope)



# final model for p values calculated with Kenward-Roger's method
m_propcue_REML = lmerTest::lmer(sqrt(value) ~ cueCond * video_phase * motion * group + 
                        (1 | participant),
                        data =  propcue_full) 

anova(m_propcue_REML, type = c("III"), ddf = "Kenward-Roger")



# emmeans
object1 <- emmeans(m_propcue_REML, ~ cueCond | motion)
object2 <- emmeans(m_propcue_REML, ~ motion | cueCond)
object3 <- emmeans(m_propcue_REML, ~ video_phase | motion)
object4 <- emmeans(m_propcue_REML, ~ motion | video_phase)

rbind(pairs(object1), pairs(object2), pairs(object3), pairs(object4), adjust = "tukey")

confint(object1, type = "response") # original units, back-transformed from sqrt scale
confint(object3, type = "response") # original units, back-transformed from sqrt scale

# visualization of interactions
emmip(m_propcue_REML, motion ~ cueCond, CIs = T)
emmip(m_propcue_REML, motion ~ video_phase, CIs = T)

emmip(m_propcue_REML, cueCond ~ video_phase | group, CIs = T)
ggsave("./figures/propcue_3way_n63.pdf")



# back-transformed estimates of comparisons
bt_object1 <- regrid(object1)
bt_object1
pairs(bt_object1) # to get SEs for back-transformed estimates

# confidence interval of comparison: estimate +/- 1.96*SE
# static: gaze - arrow
0.09336506 - (1.96*(0.010524794))
0.09336506 + (1.96*(0.010524794))

# function: gaze - arrow
0.00917435 - (1.96*(0.005109021))
0.00917435 + (1.96*(0.005109021))



# Cohen's d for comparison of gaze-arrow
summarySEwithin(propcue_full, measurevar = "value", 
                withinvars = c("motion", "cueCond"),
                idvar = "participant", na.rm = T, conf.interval=.95)

# static: gaze - arrow
n <- c(244, 238)
mean <- c(0.18569281, 0.06898589)
sd <- c(0.18014214, 0.11496000)
df <- data.frame(n,mean,sd)
pooled.sd1 <- sqrt(sum(df$sd^2 * (df$n - 1)) / (sum(df$n - 1)) )
mes2(mean[1], mean[2], pooled.sd1, n[1], n[2])


# function: gaze - arrow
n <- c(222, 224)
mean <- c(0.05731293, 0.04460339 )
sd <- c(0.09648948, 0.10302376)
df <- data.frame(n,mean,sd)
pooled.sd1 <- sqrt(sum(df$sd^2 * (df$n - 1)) / (sum(df$n - 1)) )
mes2(mean[1], mean[2], pooled.sd1, n[1], n[2])


# power for difference between gaze and arrow in static videos
# based on a paired t-test and cohen's d using a pooled sd
pwr.t.test(n = 63, d = .77, sig.level = 0.05, power = NULL, 
    type = c("paired"),
    alternative = c("two.sided"))



# MODEL DIAGNOSTICS
plot_model(m_propcue_REML, type = "diag")


# plot of individual points
ggplot( propcue_full, aes(x = cueCond, y = value, shape = group, color = group)) + 
  geom_jitter(alpha = .6) + 
  facet_wrap( ~ motion + video_phase) + 
  scale_shape_manual(values = c(19, 17))


# plot for publication
# create values
values <- with(summary(emmeans(m_propcue_REML, ~ cueCond * motion * group * video_phase), type = "response"), 
               cbind(cueCond, motion, group, video_phase, response, lower.CL,upper.CL))
values2 <- data.frame(setNames(as.data.frame(values), c("cueCond", "motion", "Group", "video_phase", "mean", "lwr","upr")))
values2 <- transform(values2,
                     motion = factor(motion),
                     cueCond = factor(cueCond), 
                     Group = factor(Group), 
                     video_phase = factor(video_phase))
values2$cueCond <- revalue(values2$cueCond, c("1" = "gaze", "2" = "arrow"))
values2$motion <- revalue(values2$motion, c("1" = "Static", "2" = "Function"))
values2$Group <- revalue(values2$Group, c("1" = "TD", "2" = "ASD"))
values2$video_phase <- revalue(values2$video_phase, c("1" = "Baseline", "2" = "Teaching (Cue Shift)"))


# plot
ggplot(values2, aes(cueCond, y = mean, ymin = lwr, ymax = upr, linetype = Group, shape = Group))+
  geom_line(aes(group = Group), size = 1, position = position_dodge(width = .2)) +
  geom_pointrange(data = values2, position=position_dodge(width = .2), size = 1) + 
  geom_errorbar(width = .3, size = 1, position = position_dodge(width = .2)) +
  labs(y = "Proportion to Cue", x = "Cue Condition") + 
  theme_bw(base_size = 12, base_family = "") + 
  theme(text = element_text(size = 30)) + 
  scale_shape_manual(values = c(19, 17)) + 
  facet_wrap(~ motion + video_phase, ncol = 2)
ggsave("./figures/proportion_cue.pdf", width = 12, height = 9, unit = "in")
```




## Mixed models - matched groups of 24 TD and 22 ASD
```{r}
# parsmonious model

# comparing models with and without slope
m_propcue_match = lmerTest::lmer(sqrt(value) ~ cueCond * video_phase * group * motion + 
                        (1 | participant),
                        data =  propcue_match, REML = F) 

m_propcue_match_withslope = lmerTest::lmer(sqrt(value) ~ cueCond * video_phase * group * motion + 
                        (1 + cueCond | participant),
                        data = propcue_match, REML = F)

anova(m_propcue_match, m_propcue_match_withslope)



# final model for p values calculated with Kenward-Roger's method
m_propcue_match_REML = lmerTest::lmer(sqrt(value) ~ cueCond * video_phase * group * motion + 
                        (1 | participant),
                        data = propcue_match) 
anova(m_propcue_match_REML, type = c("III"), ddf = "Kenward-Roger")


# post hoc testing of cue condition x motion  and cue video_phase x motion
object1 <- emmeans(m_propcue_match_REML, ~ cueCond | motion)
object2 <- emmeans(m_propcue_match_REML, ~ motion | cueCond)
object3 <- emmeans(m_propcue_match_REML, ~ video_phase |  motion)
object4 <- emmeans(m_propcue_match_REML, ~ motion | video_phase)

rbind(pairs(object1), pairs(object2), pairs(object3), pairs(object4), adjust = "tukey")

confint(object1, type = "response") # original units, back-transformed from sqrt scale
confint(object2, type = "response") # original units, back-transformed from sqrt scale

# visualization of interactions
emmip(m_propcue_match_REML, cueCond ~ motion, CIs = T)
emmip(m_propcue_match_REML, motion ~ video_phase, CIs = T)

emmip(m_propcue_match_REML, cueCond ~ video_phase | group, CIs = T)
ggsave("./figures/propcue_3way_n46.pdf")


# MODEL DIAGNOSTICS
plot_model(m_propcue_match_REML, type = "diag")
```


## Visual analysis: language, block to look at cue condition effects
```{r}
# language 
ggplot(propcue_full, aes(cueCond, value, fill = cueCond)) + 
  geom_boxplot() + 
  geom_jitter(alpha = .3) + 
  stat_summary(fun.data = give.n, geom = "text", size = 6, position=position_dodge(width=.9)) +
  stat_summary(fun.y = mean, shape = 16, col='red', geom = 'point', size = 3, position=position_dodge(width=.9)) + 
  facet_wrap(~ language + video_phase, ncol = 2) 

# block
ggplot(propcue_full, aes(cueCond, value, fill = cueCond)) + 
  geom_boxplot() + 
  geom_jitter(alpha = .3) + 
  stat_summary(fun.data = give.n, geom = "text", size = 6, position=position_dodge(width=.9)) +
  stat_summary(fun.y = mean, shape = 16, col='red', geom = 'point', size = 3, position=position_dodge(width=.9)) + 
  facet_wrap(~ block + video_phase, ncol = 2) 
```